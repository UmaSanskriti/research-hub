# Research Hub - Project Brain ðŸ§ 

> Living document to keep us organized across vibe coding sessions

**Last Updated:** 2025-01-16
**Current Status:** Multi-tier paper enrichment working, fake researcher prevention in place
**Database:** 349 researchers, 139 papers

---

## ðŸŽ¯ What This Project Does

Research Hub is an AI-powered research paper and researcher management system. It:
- Fetches papers from Semantic Scholar, OpenAlex, and Crossref
- Enriches paper metadata (abstracts, authors, citations, keywords)
- Manages researcher profiles with ORCID, affiliations, h-index
- Prevents fake researcher spam from multi-author papers
- Provides React frontend with visualizations and Claude AI chat integration

---

## ðŸ—ï¸ Architecture

### Backend (Django REST)
```
backend/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ models.py              # Paper, Researcher, Authorship, ImportJob
â”‚   â”œâ”€â”€ views.py               # REST API endpoints
â”‚   â”œâ”€â”€ serializers.py         # DRF serializers
â”‚   â”œâ”€â”€ signals.py             # Auto-enrichment on create
â”‚   â”œâ”€â”€ services/              # Business logic
â”‚   â”‚   â”œâ”€â”€ semantic_scholar_service.py    # Semantic Scholar API
â”‚   â”‚   â”œâ”€â”€ openalex_service.py            # OpenAlex API
â”‚   â”‚   â”œâ”€â”€ crossref_service.py            # Crossref API
â”‚   â”‚   â”œâ”€â”€ enrichment_service.py          # Paper enrichment (auto-triggered)
â”‚   â”‚   â”œâ”€â”€ researcher_enrichment_service.py # Researcher enrichment
â”‚   â”‚   â””â”€â”€ title_utils.py                 # Title cleaning & matching
â”‚   â””â”€â”€ management/commands/   # Management commands
â”‚       â”œâ”€â”€ enrich_papers.py               # Multi-tier fallback enrichment
â”‚       â”œâ”€â”€ import_from_semantic_scholar.py # Bulk S2 import
â”‚       â””â”€â”€ enrich_all_researchers.py      # Bulk researcher enrichment
â”œâ”€â”€ scripts/                   # Utility scripts (cleanup, testing)
â””â”€â”€ test_data/                 # Test fixtures
```

### Frontend (React + Vite)
```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pages/                 # Dashboard, Papers, Researchers, Detail pages
â”‚   â”œâ”€â”€ components/            # ClaudeChat, OrganizationGraph, etc.
â”‚   â””â”€â”€ context/               # DataContext for state management
```

---

## ðŸš¨ CRITICAL: Fake Researcher Prevention

**The Problem:** Academic APIs return papers with 50+ authors. If we create researchers for all of them, we get thousands of fake profiles.

**The Solution:** Multi-layer validation in ALL import methods:

### Validation Rules (ENFORCED EVERYWHERE)
1. **>50 authors:** Paper rejected entirely
2. **10-50 authors:** Only first author processed
3. **<10 authors:** All authors processed

### Protected Files (ALL have validation)
- âœ… `api/services/enrichment_service.py` (lines 177-195)
- âœ… `api/management/commands/enrich_papers.py` (lines 285-294)
- âœ… `api/management/commands/import_from_semantic_scholar.py` (lines 224-230)

**âš ï¸ NEVER create researchers without checking author count first!**

---

## ðŸ“Š Multi-Tier Enrichment System

Paper enrichment uses cascading fallback:

```
1. Semantic Scholar (DOI) â†’ Semantic Scholar (Title)
   â†“ (if fails)
2. OpenAlex (DOI) â†’ OpenAlex (Title)
   â†“ (if fails)
3. Crossref (DOI) â†’ Crossref (Title)
   â†“ (if fails)
4. Mark as failed with detailed reason
```

### Import Tracking
Papers have these fields for monitoring:
- `import_status`: pending, success, failed
- `import_failure_reason`: Detailed error message
- `import_attempted_at`: Last attempt timestamp
- `data_source`: semantic_scholar, openalex, crossref

### Commands
```bash
# Multi-tier enrichment (recommended)
python manage.py enrich_papers --retry-failed --limit 10

# Semantic Scholar only
python manage.py import_from_semantic_scholar --limit 10

# Enrich all researchers
python manage.py enrich_all_researchers --delay 1.0
```

---

## ðŸ”§ Key Learnings & Decisions

### What Works
- **Title cleaning is critical:** Fix "Al" â†’ "AI", remove truncation, working paper numbers
- **Multi-tier fallback:** Increased success rate from 71% to 94%
- **Author count validation:** Prevented 2,355+ fake researchers from being created
- **Crossref as fallback:** Catches papers that S2 and OpenAlex miss

### What Doesn't Work
- **OpenSpec:** Promised auto-updating specs, but just creates manual todo lists. Removed.
- **Trusting API author counts blindly:** Some APIs return garbage data (see Dennis paper incident)
- **Processing all authors:** Creates researcher spam for collaborative papers

### Architecture Decisions
- âœ… Use Django signals for auto-enrichment on paper creation
- âœ… Keep enrichment services separate from models/views (clean separation)
- âœ… Use transaction.atomic for database safety
- âœ… Track import status on papers for debugging
- âŒ Don't use OpenAPI spec generators that don't actually auto-update
- âŒ Don't create researchers for papers with >10 authors (except first author)

---

## ðŸ› Known Issues

1. **One paper still failing enrichment:**
   - "Exploring collaborative decision-making: A quasi-e"
   - All 3 services failed (title might be truncated/malformed)
   - Status: Low priority, investigate if user reports issue

2. **Log files not in .gitignore:**
   - Already covered by `*.log` pattern in backend/.gitignore
   - No action needed

3. **Some background processes still running:**
   - Various enrichment processes from testing
   - Clean up: `pkill -f "enrich_all_researchers"`

---

## ðŸ“ Recent Sessions

### Session: 2025-01-16
**Goal:** Fix fake researcher creation, implement multi-tier fallback, code cleanup

**Accomplished:**
- âœ… Added multi-tier fallback (Semantic Scholar â†’ OpenAlex â†’ Crossref)
- âœ… Created crossref_service.py for third-tier fallback
- âœ… Added title_utils.py for cleaning and similarity matching
- âœ… Fixed fake researcher bug (2,355 fake researchers from one bad paper)
- âœ… Added >10 author validation to ALL import methods
- âœ… Cleaned up 7 papers with 10-50 authors (removed 68 orphaned researchers)
- âœ… Organized codebase: created scripts/ and test_data/ folders
- âœ… Code cleanup: removed unused imports, added missing packages
- âœ… Removed OpenSpec (wasn't auto-updating as promised)
- âœ… Created this PROJECT_NOTES.md file
- âœ… Committed and pushed all changes to GitHub

**Final Stats:**
- 349 researchers (cleaned from 2,772)
- 139 papers
- 17/18 papers successfully enriched (94% success rate)

**Database State:**
```sql
-- Current counts
SELECT COUNT(*) FROM api_researcher;  -- 349
SELECT COUNT(*) FROM api_paper;       -- 139
SELECT COUNT(*) FROM api_authorship;  -- ~350-400
```

---

## ðŸš€ Next Time We Code

### Quick Start Checklist
1. Check database counts: `python manage.py shell -c "from api.models import Researcher, Paper; print(f'{Researcher.objects.count()} researchers, {Paper.objects.count()} papers')"`
2. Check for background processes: `pgrep -f "enrich_all_researchers"`
3. Check git status: `git status`
4. Review this file for context

### Potential Next Steps
- [ ] Add researcher deduplication (check for duplicate names/ORCIDs)
- [ ] Implement paper deduplication before import (check DOI/title)
- [ ] Add admin interface for managing failed imports
- [ ] Create visualization for import success rates over time
- [ ] Add bulk delete for researchers with no papers
- [ ] Consider adding arXiv as 4th tier fallback
- [ ] Add rate limiting metrics/monitoring

### Commands to Remember
```bash
# Start dev servers
cd backend && venv/bin/python manage.py runserver
cd frontend && npm run dev

# Database management
python manage.py migrate
python manage.py shell

# Enrichment
python manage.py enrich_papers --retry-failed
python manage.py enrich_all_researchers --delay 1.0

# Git
git add -A && git commit -m "..." && git push
```

---

## ðŸ“š Important Files to Know

### Must Read Before Changing
- `api/models.py` - Database schema, add fields here
- `api/services/enrichment_service.py` - Auto-enrichment logic (triggered by signals)
- `api/signals.py` - Auto-enrichment triggers on paper/researcher creation

### Frequently Modified
- `api/views.py` - API endpoints
- `api/management/commands/enrich_papers.py` - Multi-tier enrichment
- `frontend/src/pages/*` - React pages

### Reference Only
- `backend/scripts/` - Utility scripts (cleanup, testing)
- `backend/test_data/` - Test fixtures

---

## ðŸ”— External Services

### Semantic Scholar API
- **Rate Limit:** ~100 requests/second (generous)
- **Best For:** CS/AI papers, detailed author info
- **Package:** `semanticscholar==0.11.0`

### OpenAlex API
- **Rate Limit:** Polite = 10 req/s, requires email in User-Agent
- **Best For:** Broad coverage, open access info
- **Package:** `pyalex==0.14`

### Crossref API
- **Rate Limit:** 50 req/s (polite pool with email)
- **Best For:** DOI resolution, publication metadata
- **Package:** `habanero==1.2.6`

### Azure OpenAI (Claude Chat)
- **Model:** Uses environment variable `AZURE_OPENAI_*`
- **Used For:** Frontend chat interface
- **Package:** `openai>=1.0.0`

---

## ðŸ’¡ Tips for Future Sessions

1. **Always check researcher count first** - If it's way higher than expected, fake researcher bug is back
2. **Test enrichment on 10 papers max** - Before running on full dataset
3. **Use `--limit` flag** - All enrichment commands support it
4. **Check import_status field** - To see which papers failed and why
5. **Background processes** - Use `nohup` for long-running tasks, check with `pgrep`
6. **Git often** - Commit after each major feature/fix
7. **Read this file first** - Save time understanding context

---

## ðŸŽ¨ Frontend Notes

### Tech Stack
- React 18 + Vite
- React Router for navigation
- Custom hooks for data fetching
- D3.js for network visualization (OrganizationGraph)
- Tailwind CSS (likely, based on style patterns)

### Key Components
- `ClaudeChat.jsx` - AI chat interface (Azure OpenAI)
- `OrganizationGraph.jsx` - Network visualization of researchers/papers
- `DataContext.jsx` - Centralized state management

### API Integration
Frontend expects these endpoints:
- `/api/papers/` - List/detail/create papers
- `/api/researchers/` - List/detail researchers
- `/api/researchers/{id}/enrich/` - Trigger enrichment

---

_Last session: Fighting fake researchers and winning. Next session: TBD based on vibe._
